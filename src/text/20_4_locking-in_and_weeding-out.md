---
ordinal: 20.4
title: locking-in and weeding-out
---

# 20.4 LOCKING-IN AND WEEDING-OUT

Most language-words are linked to many different polynemes, which correspond to the many "meaning-senses" of each word. To arouse so many polynemes at once would often lead to conflicts as each tries to set one's agencies into different states at the same time. If there are no other contextual clues, some of these conflicts would be resolved in accord with their connection strengths. For example, upon hearing "The astronomer married the star," a playwright would tend to give priority to the theatrical sense of "star," whereas an astronomer would think first of a distant sun, other things being equal.

But other things are not usually equal. At every moment a person's mind is already involved with some "context" in which many agents are actively aroused. Because of this, as each new word arouses different polynemes, these will compete to change the states of those agents. Some of those changes will gain support as certain combinations of agents reinforce one another. Others that lose support and are left to stand alone will tend to weaken, and most ambiguities will thus be weeded out. In a few cycles, the entire system will firmly "lock in" on one meaning-sense for each word and firmly suppress the rest.

A computer program that actually worked this way was developed by Jordan Pollack and David Waltz. When applied to the sentence, "John shot two bucks," and supplied with the faintest context clue, the program would indeed usually settle into a single, consistent interpretation. In other words, after a few cycles, the agents ended up in a pattern of mutually supporting activities in which only one sense of each word remained strongly active while all the other meaning- senses were suppressed. Thereafter, whether this "alliance" of word-senses was involved with hunting or with gambling, it became so self-supporting that it could resist any subsequent small signal from outside. In effect, the system had found a stable, unambiguous interpretation of the sentence.

What can be done if such a system settles on a wrong interpretation? Suppose, for example, that an "outdoors" clue had already made the system decide that John was hunting, but later it was told that John was gambling in the woods. Since a single new context clue might not be able to overcome an established alliance of meaning-senses, it might be necessary for some higher-level agency to start the system out afresh. What if the end result of locking-in were unacceptable to other agencies? Simply repeating the process would only lead to making the same mistake again. One way to prevent that would be to record which meaning-senses were adopted in the previous cycle and suppress them temporarily at the start of the next cycle. This would probably produce a new interpretation.

There is no guarantee that this method will always find an interpretation that yields a meaning consistent with all the words of the sentence. Then, if the locking-in process should fail, the listener will be confused. There are other methods that one could attempt, for example, to imagine a new context and then restart the ring-closing process. But no single method will always work. To use the power of language, one must acquire many different ways to understand.
